# Портфолио моих проектов в области DataScience

- **Исследование объявлений о продаже квартир в Санкт-Петербурге и Ленинградской области**

Файлы: *SPb-real-estate-cost-analysis.ipynb*

Задача:  Выяснить, от чего зависит рыночная стоимость недвижимости. Это позволит построить автоматизированную систему для выявления аномалий и мошеннической деятельности. 

Данные: csv-файл, 22 признака, 23699 объектов

Библиотеки: pandas, numpy, matplotlib, seaborn

Много времени уделено очистке данных. Обработал текстовые признаки: убрал скрытые дубли, систематизировал типы населённых пунктов (это позволило проанализировать рынок городов, посёлков, деревень и ПГТ отдельно, выделить некоторые особенности). Исключил слишком быстрые и медленные продажи, очистил данные от выбросов. Часть выбросов и пропусков в данных анализировал вручную, разбираясь с особенностями строительных норм и правил. В результате получил максимально корректный набор данных.
В работе широко использовал возможности seaborn: все результаты наглядно визуализированы. Для поиска взаимосвязей использовал, в том числе, корреляционный анализ и тепловые карты для отображения результатов. 

Результат:  Выявил, что между регионом и Санкт-Петербургом основные тенденции схожи. Однако Санкт-Петербург сильно выделяется в регионе уровнем цен, а в Санкт-Петербурге аналогично выделяется центральная зона. Анализ показал, что в основном рыночную стоимость определяют место расположения и расстояние до центра города, площадь, число комнат, этаж. Кроме того, на стоимость влияет год подачи объявления и стоимость квадратного метра. 
Для Санкт-Петербурга дополнительно проанализировал влияние высоты потолков, числа парков и водоёмов в радиусе 3км.

- **Определение тональности комментариев**

Файлы: *Binary-text-classification.ipynb*

Задача:  Нужно обучить модель классифицировать комментарии на позитивные и негативные. Целевая метрика - f1. Нужно получить значение на тестовой выборке не ниже 0.75.

Данные: csv-файл, 159571 объектов, два признака (текст комментария и метка класса)

Библиотеки: pandas, numpy, re, torch, csv, transformers(BERT), spacy, nltk, sklearn, catboost

Использовал варианты TfidfVectorizer + LogisticRegression, spaCy TextCategorizer, BERT + LogisticRegression. Важным этапом работы с BERT была оптимизация набора данных по особому алгоритму. В его основе - упорядочивание текстовых векторов выборки перед разбиением на батчи. Это позволило сильно сократить время и объём памяти. Также сравнил два варианта лемматизации: на базе Natural Language Toolkit и на базе spaCy. Выбрал spaCy, как более быстрый и корректный.

Результат: Лучше всего себя показала комбинация TfidfVectorizer + LogisticRegression, достигнута целевая метрика 0.78.


- **Выбор региона для разработки нефтяных месторождений**

Файлы: *Oil-field-volume-forecast.ipynb*

Задача: разработать модель для прогноза объёма нефти в месторождении. Оценить риск убытков при разработке региона на основании прогнозов модели. Рекомендовать один из регионов к разработке.

Библиотеки: pandas, numpy, scipy, matplotlib, seaborn, plotly, sklearn, hdbscan, plotly, xgboost, catboost

В данной задаче я удачно использовал feature engineering: увидел при анализе, что распределение признаков во всех регионах неравномерное, признаки принадлежат разным кластерам. Ввёл признак - метку класса, использовал собственные методы кластеризации. Некоторые метрики (например r^2) удалось улучшить почти в полтора раза. Также в пределах 5-10% удалось улучшить метрики rmse и mae. Все модели в итоге обучены на двух признаках: метке или значении функции вероятности принадлежности к кластеру и признаке f2. Модели простые и понятные, легко интерпретируемые.

Результат: На базе построенных моделей выполнена оценка трёх регионов с точки зрения рисков и потенциальной прибыли от разработки месторождений нефти. Сымитирована 1000 случаев исследования и разработки каждого региона. Для имитации исследований использована техника повторного отбора: bootstrap. К разработке рекомендован один из регионов.